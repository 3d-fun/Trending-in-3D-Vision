{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trending in 3D Vision\n",
    "Deep learning not only provides good optimization techniques on feaure engineering, but also gives us unimaginable possibility to combine our intutions into research that could explore this 3D world better; usually people will divide 3D vision into stereo vision, multi-view, monucular based 3D, but here we found it's better to sort out topics that could distinguish from 2D, but also connect with 2D, and show a better over-view on the fidld of 3D vision research. Also, people have done paper collections [here](https://github.com/flamato/3D-computer-vision-resources), but they don't usually give us a good bird view on research happening in this field. Basically, these are the three reasons why we create this special collection by summerizing the general ideas behind some most recent papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.  Single Image 3D & Monucular Video 3D\n",
    "[[Mahj. et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Mahjourian_Unsupervised_Learning_of_CVPR_2018_paper.pdf)] Unsupervised Learning of Depth and Ego-Motion from Monocular Video Using 3D Geometric Constraints [[Project](https://sites.google.com/view/vid2depth)] [[Code](https://github.com/tensorflow/models/tree/master/research/vid2depth)]\n",
    "\n",
    "[[Yang et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_LEGO_Learning_Edge_CVPR_2018_paper.pdf)] LEGO: Learning Edge with Geometry all at Once by Watching Videos  [[Demo](https://www.youtube.com/watch?v=40-GAgdUwI0)] [[Code](https://github.com/zhenheny/LEGO)]\n",
    "\n",
    "[[Jiang et al. IJCV 2018](https://arxiv.org/pdf/1704.00112.pdf)] Configurable 3D Scene Synthesis and 2D Image Rendering with Per-Pixel Ground Truth using Stochastic Grammars [[Demo](https://vimeo.com/211226594)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Perception Beyond Visiable \n",
    "[[Song et al. CVPR 2018](https://arxiv.org/abs/1712.04569)] Im2Pano3D: Extrapolating 360° Structure and Semantics Beyond the Field of View [[Project](http://im2pano3d.cs.princeton.edu/)] [[Code](https://github.com/shurans/im2pano3d/)]\n",
    "\n",
    "[[Tulsiani et al. ECCV 2018](https://arxiv.org/pdf/1807.10264.pdf)] Layer-structured 3D Scene Inference\n",
    "via View Synthesis [[Project](https://shubhtuls.github.io/lsi/)] [[Code](https://github.com/google/layered-scene-inference)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pose Estimation \n",
    "\n",
    "#### 3.1 Scene Layout and Object Pose \n",
    "[[Tulsiani et al. ECCV 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Tulsiani_Factoring_Shape_Pose_CVPR_2018_paper.pdf)] Factoring Shape, Pose, and Layout from the 2D Image of a 3D Scene\n",
    "\n",
    "[[Huang et al. NIPS 2018](https://arxiv.org/pdf/1810.13049.pdf)] Cooperative Holistic Scene Understanding: Unifying3D Object, Layout, and Camera Pose Estimation \n",
    "\n",
    "[[Tekin et al. CVPR 2018](https://arxiv.org/pdf/1711.08848.pdf)] Real-Time Seamless Single Shot 6D Object Pose Prediction  [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "\n",
    "#### 3.2 Body Pose \n",
    "\n",
    "[[Joo et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Joo_Total_Capture_A_CVPR_2018_paper.pdf)] Total Capture: A 3D Deformation Model for Tracking Faces, Hands, and Bodies [[Project](http://www.cs.cmu.edu/~hanbyulj/totalcapture/)] [[Supp.](http://www.cs.cmu.edu/~hanbyulj/totalcapture/totalBody_camready_supp.pdf)]\n",
    "\n",
    "[[Riza et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Guler_DensePose_Dense_Human_CVPR_2018_paper.pdf)] \n",
    "Dense Human Pose Estimation In The Wild [[Project](http://densepose.org/)] [[Code](https://github.com/facebookresearch/DensePose)]\n",
    "\n",
    "[[Groueix et al. ECCV 2018](https://arxiv.org/pdf/1806.05228.pdf)] 3D-CODED : 3D Correspondences by Deep Deformation  [[Project](http://imagine.enpc.fr/~groueixt/3D-CODED/)] [[Code](https://github.com/ThibaultGROUEIX/3D-CODED)]\n",
    "\n",
    "\n",
    "[[Pavl. et al. CVPR 2018](https://arxiv.org/pdf/1805.04092.pdf)] Learning to Estimate 3D Human Pose and Shape from a Single Color Image [[Project](https://www.seas.upenn.edu/~pavlakos/projects/humanshape/)]\n",
    "\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "\n",
    "#### 3.3 Face Pose\n",
    "[[Genova et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/papers/Genova_Unsupervised_Training_for_CVPR_2018_paper.pdf)] Unsupervised Training for 3D Morphable Model Regression  [[Project]()] [[Code](https://github.com/google/tf_mesh_renderer)]\n",
    "\n",
    "[[Deng et al. CVPR 2018](https://arxiv.org/pdf/1712.04695.pdf)] UV-GAN: Adversarial Facial UV Map Completion for Pose-invariant Face\n",
    "Recognition  [[Project]()] [[Code]()]\n",
    "\n",
    "[[Feng et al. ECCV 2018](https://arxiv.org/pdf/1803.07835v1.pdf)] Joint 3D Face Reconstruction and Dense Alignment with Position Map Regression Network [[Code](https://github.com/YadiraF/PRNet)] [[Video](https://www.youtube.com/watch?v=tXTgLSyIha8&feature=youtu.be)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "#### 3.4 Hand Pose\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Key Points Detection\n",
    "[[Suwa. et al. NIPS 2018](https://arxiv.org/pdf/1807.03146.pdf)] Discovery of Latent 3D Keypoints via\n",
    "End-to-end Geometric Reasoning  [[Project](https://keypointnet.github.io/)] [[Code](https://github.com/tensorflow/models/tree/master/research/keypointnet)]\n",
    "\n",
    "[[Zhou et al. ECCV 2018](https://arxiv.org/pdf/1712.05765.pdf)] Unsupervised Domain Adaptation for 3D\n",
    "Keypoint Estimation via View Consistency [[Code](https://github.com/xingyizhou/3DKeypoints-DA)]  [[Results](https://drive.google.com/file/d/1UtlL7moKtNoVGyqWGRn8_c_57dwiqlVm/view)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 3D point clouds Processing \n",
    "#### 5.1 3D Neural Network\n",
    "[[Tata. et al. CVPR 2018](http://openaccess.thecvf.com/content_cvpr_2018/CameraReady/0144.pdf)] Tangent Convolutions for Dense Prediction in 3D [[Code](https://github.com/tatarchm/tangent_conv)]\n",
    "\n",
    "[[Su et al. CVPR 2018](https://arxiv.org/abs/1802.08275)] SPLATNet: Sparse Lattice Networks for Point Cloud Processing \n",
    "[[Project](http://siyuanhuang.com/cooperative_parsing/main.html)] [[Code](https://github.com/NVlabs/splatnet)]\n",
    "\n",
    "[[Qi et al. NIPS 2017](https://arxiv.org/abs/1706.02413)] PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space  [[Project](http://stanford.edu/~rqi/pointnet2/)] [[Code](https://github.com/charlesq34/pointnet2)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "\n",
    "#### 5.2 3D Object Detection\n",
    "\n",
    "[[Qi et al. CVPR 2018](https://arxiv.org/pdf/1711.08488.pdf)] Frustum PointNets for 3D Object Detection from RGB-D Data  [[Project](http://stanford.edu/~rqi/frustum-pointnets/)] [[Code](https://github.com/charlesq34/frustum-pointnets)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "\n",
    "#### 5.3 Point Registration & Rendering\n",
    "[[Kim et al. ECCV 2018](https://arxiv.org/pdf/1807.02587.pdf)] Fast and Accurate Point Cloud Registration using Trees of Gaussian Mixtures  [[Project](https://research.nvidia.com/publication/2018-09_HGMM-Registration)] [[Video](https://www.youtube.com/watch?v=Bczht9CspiY)]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Object-aware SLAM\n",
    "[[Rünz et al. ISMAR 2018](https://arxiv.org/pdf/1804.09194.pdf)] MaskFusion: Real-Time Recognition, Tracking and Reconstruction of Multiple Moving Objects [[Project](http://visual.cs.ucl.ac.uk/pubs/maskfusion/index.html)] [[Code](https://github.com/martinruenz/maskfusion)] [[Demo](http://visual.cs.ucl.ac.uk/pubs/maskfusion/MaskFusion.webm)]\n",
    "\n",
    "[[Bloesch et al. CVPR 2018](https://arxiv.org/abs/1804.00874)] CodeSLAM — Learning a Compact, Optimisable Representation for Dense Visual SLAM [[Project](http://www.imperial.ac.uk/dyson-robotics-lab/projects/codeslam/)] [[Video](https://www.youtube.com/watch?v=PbSggzaZWAQ&t=1s)]\n",
    "\n",
    "[[McCo. et al. 3DV 2018](https://www.doc.ic.ac.uk/~sleutene/publications/fusion_plusplus_3dv_camera_ready.pdf)] Fusion++: Volumetric Object-Level SLAM [[Video](https://www.youtube.com/watch?v=2luKNC03x4k&feature=youtu.be)]\n",
    "\n",
    "[[Zhou et al. ECCV 2018](https://arxiv.org/pdf/1808.01900.pdf)] DeepTAM: Deep Tracking and Mapping  [[Project](https://lmb.informatik.uni-freiburg.de/people/zhouh/deeptam/)] [[Code](https://github.com/lmb-freiburg/deeptam)]\n",
    "\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Project]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 2018\n",
    "[[Trem. et al. CVPR 2018 Workshop](https://research.nvidia.com/publication/2018-06_Falling-Things)] Falling Things: A Synthetic Dataset for 3D Object Detection and Pose Estimation\n",
    "\n",
    "[[Sun et al. CVPR 2018](https://arxiv.org/pdf/1804.04610.pdf)] Pix3D: Dataset and Methods for Single-Image 3D Shape Modeling [[Dataset](https://github.com/xingyuansun/pix3d)]\n",
    "\n",
    "[[et al. ]()]   [[Dataset]()] [[Code]()]\n",
    "\n",
    "[[et al. ]()]   [[Dataset]()] [[Code]()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Misc & Resources: \n",
    "[Bridge to CVPR 3D workshop](https://bridgesto3d.github.io/#schedule) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
